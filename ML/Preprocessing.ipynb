{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 特征抽取\n",
    "## sklearn相关API\n",
    "### 1、字典\n",
    "### 2、文本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jieba  # 用于中文特征处理\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-09T16:52:45.484658Z",
     "end_time": "2023-07-09T16:52:47.048295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   0.   0. 100.]\n",
      " [  0.   1.   0.  50.]\n",
      " [  0.   0.   1.  10.]]\n",
      "--------------------------------------------------\n",
      "['city=北京' 'city=南京' 'city=天津' 'temperature']\n",
      "--------------------------------------------------\n",
      "[{'city=北京': 1.0, 'temperature': 100.0}, {'city=南京': 1.0, 'temperature': 50.0}, {'city=天津': 1.0, 'temperature': 10.0}]\n"
     ]
    }
   ],
   "source": [
    "def dictvec():\n",
    "    \"\"\"\n",
    "    字典数据特征提取\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 参数saprse  稀疏，对于矩阵中的参数存储采用稀疏矩阵的方法\n",
    "    dict = DictVectorizer(sparse=False)\n",
    "    data = dict.fit_transform([{'city': '北京', 'temperature': 100},\n",
    "                               {'city': '南京', 'temperature': 50},\n",
    "                               {'city': '天津', 'temperature': 10}])\n",
    "\n",
    "    print(data)  # 返回sparse矩阵\n",
    "    print('-' * 50)\n",
    "    print(dict.get_feature_names_out())  # 转换特征name\n",
    "    print('-' * 50)\n",
    "    print(dict.inverse_transform(data))  # 按原格式转换数据\n",
    "    return None\n",
    "\n",
    "\n",
    "dictvec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T09:19:08.453169Z",
     "end_time": "2023-07-05T09:19:08.472048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "--------------------------------------------------\n",
      "[[0 1 2 1 0 1 1 0]\n",
      " [1 1 1 0 1 1 0 1]\n",
      " [0 1 1 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "['dislike' 'is' 'life' 'like' 'long' 'python' 'short' 'too']\n",
      "--------------------------------------------------\n",
      "[array(['life', 'is', 'short', 'like', 'python'], dtype='<U7'), array(['life', 'is', 'python', 'too', 'long', 'dislike'], dtype='<U7'), array(['life', 'is', 'short'], dtype='<U7')]\n"
     ]
    }
   ],
   "source": [
    "def convec():\n",
    "    \"\"\"\n",
    "    文本数据提取\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 实例化CountVectorizer\n",
    "    # max_df, min_df整数：指每个词的所有文档词频数不小于最小值，出现该词的文档数目小于等于max_df\n",
    "    # max_df, min_df小数：每个词的次数／所有文档数量\n",
    "    # min_df=2\n",
    "    vector = CountVectorizer()\n",
    "    res = vector.fit_transform([\"life is  short,i like python life\",\n",
    "                                \"life is too long,i dislike python\",\n",
    "                                \"life is short\"])\n",
    "    print(res)\n",
    "    print('-' * 50)\n",
    "    print(res.toarray())\n",
    "    print('-' * 50)\n",
    "    print(vector.get_feature_names_out())  # 按字母排序\n",
    "    print('-' * 50)\n",
    "    print(vector.inverse_transform(res))\n",
    "    return None\n",
    "\n",
    "\n",
    "convec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T09:24:48.987424Z",
     "end_time": "2023-07-05T09:24:49.006533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python' '不用' '人生漫长' '人生苦短' '喜欢']\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 0)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "[[2 0 0 1 1]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def countvec():\n",
    "    \"\"\"\n",
    "    汉字进行文本数据特征提取\n",
    "    默认对单个汉字不统计\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform([\"人生苦短，我 喜欢 python python\", \"人生漫长，不用 python\"])\n",
    "    print(cv.get_feature_names_out())\n",
    "    print(data)\n",
    "    print(data.toarray())\n",
    "    return None\n",
    "\n",
    "\n",
    "countvec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T09:28:29.820670Z",
     "end_time": "2023-07-05T09:28:29.834192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。 我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。 如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "--------------------------------------------------\n",
      "  (0, 6)\t2\n",
      "  (0, 26)\t2\n",
      "  (0, 22)\t2\n",
      "  (0, 12)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 20)\t1\n",
      "  (1, 18)\t3\n",
      "  (1, 28)\t2\n",
      "  (1, 23)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 35)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 34)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 21)\t1\n",
      "  (2, 4)\t4\n",
      "  (2, 25)\t1\n",
      "  (2, 5)\t3\n",
      "  (2, 1)\t1\n",
      "  (2, 29)\t2\n",
      "  (2, 13)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 33)\t1\n",
      "--------------------------------------------------\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "--------------------------------------------------\n",
      "[array(['今天', '残酷', '明天', '后天', '美好', '绝对', '大部分', '晚上', '所以', '每个', '不要',\n",
      "       '放弃'], dtype='<U4'), array(['我们', '看到', '星系', '光是在', '几百万年', '之前', '发出', '这样', '宇宙', '过去'],\n",
      "      dtype='<U4'), array(['我们', '如果', '只用', '一种', '方式', '了解', '某样', '事物', '不会', '真正', '含义',\n",
      "       '秘密', '取决于', '如何', '联系'], dtype='<U4')]\n"
     ]
    }
   ],
   "source": [
    "def cutword():\n",
    "    \"\"\"\n",
    "    导入jieba模块，对中文字符尽可能的正确分词\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    con1 = jieba.cut(\"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\")\n",
    "\n",
    "\n",
    "    con2 = jieba.cut(\"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\")\n",
    "\n",
    "    con3 = jieba.cut(\n",
    "    \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\")\n",
    "\n",
    "    print(type(con1))\n",
    "    content1 = list(con1)\n",
    "    content2 = list(con2)\n",
    "    content3 = list(con3)\n",
    "\n",
    "    c1 = ' '.join(content1)\n",
    "    c2 = ' '.join(content2)\n",
    "    c3 = ' '.join(content3)\n",
    "\n",
    "    return c1,c2,c3\n",
    "\n",
    "def hanzivec():\n",
    "    c1,c2,c3 = cutword()  # jieba 处理后返回的是一个生成器\n",
    "    print(c1,c2,c3)\n",
    "    print('-' * 50)\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform([c1,c2,c3])\n",
    "    print(data)\n",
    "    print('-' * 50)\n",
    "    print(cv.get_feature_names_out())\n",
    "    print('-' * 50)\n",
    "    print(cv.inverse_transform(data))\n",
    "\n",
    "hanzivec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T09:34:37.802972Z",
     "end_time": "2023-07-05T09:34:37.831173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。 我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。 如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "<class 'list'>\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0.         0.         0.21821789 0.         0.         0.\n",
      "  0.43643578 0.         0.         0.         0.         0.\n",
      "  0.21821789 0.         0.21821789 0.         0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.43643578 0.\n",
      "  0.21821789 0.         0.43643578 0.21821789 0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.2410822 ]\n",
      " [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n",
      "  0.         0.         0.         0.         0.15698297 0.15698297\n",
      "  0.         0.15698297 0.         0.15698297 0.15698297 0.\n",
      "  0.1193896  0.         0.         0.15698297 0.         0.\n",
      "  0.         0.15698297 0.         0.         0.         0.31396594\n",
      "  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 规范{'l1'，'l2'}，默认='l2'\n",
    "# 每个输出行都有单位范数，或者：\n",
    "#\n",
    "# 'l2'：向量元素的平方和为 1。当应用 l2 范数时，两个向量之间的余弦相似度是它们的点积。\n",
    "#\n",
    "# 'l1'：向量元素的绝对值之和为 1。参见preprocessing.normalize。\n",
    "\n",
    "# smooth_idf布尔值，默认 = True\n",
    "# 通过在文档频率上加一来平滑 idf 权重，就好像看到一个额外的文档包含集合中的每个术语恰好一次。防止零分裂。\n",
    "\n",
    "def tfidfvec():\n",
    "    \"\"\"\n",
    "    中文特征值化,计算tfidf值\n",
    "    tf-idf  提取高频、尽量独有、特征明显词汇的词频\n",
    "    tf:词频\n",
    "    idf:逆文档频率，log(总文档数/改词文档数量)\n",
    "    tf*idf  来代表重要性程度:\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    c1, c2, c3 = cutword()\n",
    "\n",
    "    print(c1, c2, c3)\n",
    "    print(type([c1, c2, c3]))\n",
    "    tf = TfidfVectorizer()\n",
    "\n",
    "    data = tf.fit_transform([c1, c2, c3])\n",
    "\n",
    "    print(tf.get_feature_names_out())\n",
    "    print(type(data))\n",
    "    print(data.toarray())\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "tfidfvec()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-05T10:03:55.835657Z",
     "end_time": "2023-07-05T10:03:55.849656Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征处理，归一化、标准化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         1.         0.83333333]\n",
      " [0.5        0.5        0.6        1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def mm():\n",
    "    \"\"\"\n",
    "    归一化处理\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mm = MinMaxScaler(feature_range=(0,1))\n",
    "    data = mm.fit_transform([[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]])\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    return None\n",
    "\n",
    "mm()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T19:50:43.645999Z",
     "end_time": "2023-07-06T19:50:43.655700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.06904497 -1.35873244  0.98058068]\n",
      " [-0.26726124  0.33968311  0.39223227]\n",
      " [ 1.33630621  1.01904933 -1.37281295]]\n",
      "[2.33333333 3.         1.33333333]\n",
      "[1.55555556 8.66666667 2.88888889]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def stand():\n",
    "    std = StandardScaler()\n",
    "\n",
    "    data = std.fit_transform([[1., -1., 3.], [2., 4., 2.], [4., 6., -1.]])\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    print(std.mean_)\n",
    "    print(std.var_)\n",
    "    print(std.n_samples_seen_) # 样本数\n",
    "\n",
    "    return None\n",
    "\n",
    "stand()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T20:32:42.564242Z",
     "end_time": "2023-07-06T20:32:42.586354Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 缺失值处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.        ]\n",
      " [3.66666667 3.        ]\n",
      " [7.         6.        ]\n",
      " [3.         2.        ]]\n"
     ]
    }
   ],
   "source": [
    "def im():\n",
    "    # 缺失值处理，simpleimputer  只能替换nan，当出现其他符号表示的空值需要进行replace\n",
    "   im = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "   data = im.fit_transform([[1, 2], [np.nan, 3], [7, 6], [3, 2]])\n",
    "\n",
    "   print(data)\n",
    "\n",
    "   return  None\n",
    "im()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T20:34:05.540198Z",
     "end_time": "2023-07-06T20:34:06.143689Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 特征选择\n",
    "## 选择合适特征可以降低冗余、噪声\n",
    "### 一般的特征选择，取其中部分，常见有filter、embedded、wrapper（掌握前两个）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [4]\n",
      " [1]]\n",
      "剩余特征编号[2]\n"
     ]
    }
   ],
   "source": [
    "def var():\n",
    "    \"\"\"\n",
    "    特征选择--删除低方差的特征\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    var = VarianceThreshold(threshold=1) # default=0\n",
    "\n",
    "    data = var.fit_transform([[0, 2, 0, 3],\n",
    "                              [0, 1, 4, 3],\n",
    "                              [0, 1, 1, 3]])\n",
    "    print(data)\n",
    "\n",
    "    print('剩余特征编号%s' % var.get_support(True))\n",
    "    return None\n",
    "var()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T20:48:29.451857Z",
     "end_time": "2023-07-06T20:48:29.468261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28620952e-15  3.82970843e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "source": [
    "def pca():\n",
    "    \"\"\"\n",
    "    特征选择--降维，对二维平面点降维到一条直线（所有点到该直线垂直距离之和最短）上的距离坐标\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=0.9)  # 保留原有特征的90%\n",
    "\n",
    "    data = pca.fit_transform([[2, 8, 4, 5], [6, 3, 0, 8], [5, 4, 9, 1]])\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    return None\n",
    "\n",
    "pca()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-06T20:51:20.187697Z",
     "end_time": "2023-07-06T20:51:20.209225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
